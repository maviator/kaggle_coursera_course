{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%store -r __importRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maviator/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "__importRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#sales = pd.read_csv('../input/train.csv')\n",
    "#all_data = pd.read_csv('all_data.csv')\n",
    "all_data = pd.read_csv('../input/all_data_1_2_3_12_cat.csv')\n",
    "#test = pd.read_csv('../input/test_1_2_3_12_cat.csv')\n",
    "#test = pd.read_csv('../input/test.csv')\n",
    "#items = pd.read_csv(\"../input/items.csv\")\n",
    "#categories = pd.read_csv(\"../input/item_categories.csv\")\n",
    "#print (sales.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reduce_mem_usage(props):\n",
    "    start_mem_usg = props.memory_usage().sum() / 1024**2 \n",
    "    print(\"Memory usage of properties dataframe is :\",start_mem_usg,\" MB\")\n",
    "    NAlist = [] # Keeps track of columns that have missing values filled in. \n",
    "    for col in props.columns:\n",
    "        if props[col].dtype != object:  # Exclude strings\n",
    "            \n",
    "            # Print current column type\n",
    "            print(\"******************************\")\n",
    "            print(\"Column: \",col)\n",
    "            print(\"dtype before: \",props[col].dtype)\n",
    "            \n",
    "            # make variables for Int, max and min\n",
    "            IsInt = False\n",
    "            mx = props[col].max()\n",
    "            mn = props[col].min()\n",
    "            \n",
    "            # Integer does not support NA, therefore, NA needs to be filled\n",
    "            if not np.isfinite(props[col]).all(): \n",
    "                NAlist.append(col)\n",
    "                props[col].fillna(mn-1,inplace=True)  \n",
    "                   \n",
    "            # test if column can be converted to an integer\n",
    "            asint = props[col].fillna(0).astype(np.int64)\n",
    "            result = (props[col] - asint)\n",
    "            result = result.sum()\n",
    "            if result > -0.01 and result < 0.01:\n",
    "                IsInt = True\n",
    "\n",
    "            \n",
    "            # Make Integer/unsigned Integer datatypes\n",
    "            if IsInt:\n",
    "                if mn >= 0:\n",
    "                    if mx < 255:\n",
    "                        props[col] = props[col].astype(np.uint8)\n",
    "                    elif mx < 65535:\n",
    "                        props[col] = props[col].astype(np.uint16)\n",
    "                    elif mx < 4294967295:\n",
    "                        props[col] = props[col].astype(np.uint32)\n",
    "                    else:\n",
    "                        props[col] = props[col].astype(np.uint64)\n",
    "                else:\n",
    "                    if mn > np.iinfo(np.int8).min and mx < np.iinfo(np.int8).max:\n",
    "                        props[col] = props[col].astype(np.int8)\n",
    "                    elif mn > np.iinfo(np.int16).min and mx < np.iinfo(np.int16).max:\n",
    "                        props[col] = props[col].astype(np.int16)\n",
    "                    elif mn > np.iinfo(np.int32).min and mx < np.iinfo(np.int32).max:\n",
    "                        props[col] = props[col].astype(np.int32)\n",
    "                    elif mn > np.iinfo(np.int64).min and mx < np.iinfo(np.int64).max:\n",
    "                        props[col] = props[col].astype(np.int64)    \n",
    "            \n",
    "            # Make float datatypes 32 bit\n",
    "            else:\n",
    "                props[col] = props[col].astype(np.float32)\n",
    "            \n",
    "            # Print new column type\n",
    "            print(\"dtype after: \",props[col].dtype)\n",
    "            print(\"******************************\")\n",
    "    \n",
    "    # Print final result\n",
    "    print(\"___MEMORY USAGE AFTER COMPLETION:___\")\n",
    "    mem_usg = props.memory_usage().sum() / 1024**2 \n",
    "    print(\"Memory usage is: \",mem_usg,\" MB\")\n",
    "    print(\"This is \",100*mem_usg/start_mem_usg,\"% of the initial size\")\n",
    "    return props, NAlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add date_block_num for test with value 34 (next month)\n",
    "test['date_block_num'] = 34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Memory usage of properties dataframe is :', 1582, ' MB')\n",
      "******************************\n",
      "('Column: ', 'shop_id')\n",
      "('dtype before: ', dtype('int64'))\n",
      "('dtype after: ', dtype('uint8'))\n",
      "******************************\n",
      "******************************\n",
      "('Column: ', 'item_id')\n",
      "('dtype before: ', dtype('int64'))\n",
      "('dtype after: ', dtype('uint16'))\n",
      "******************************\n",
      "******************************\n",
      "('Column: ', 'date_block_num')\n",
      "('dtype before: ', dtype('int64'))\n",
      "('dtype after: ', dtype('uint8'))\n",
      "******************************\n",
      "******************************\n",
      "('Column: ', 'target')\n",
      "('dtype before: ', dtype('int64'))\n",
      "('dtype after: ', dtype('int16'))\n",
      "******************************\n",
      "******************************\n",
      "('Column: ', 'target_shop')\n",
      "('dtype before: ', dtype('int64'))\n",
      "('dtype after: ', dtype('int16'))\n",
      "******************************\n",
      "******************************\n",
      "('Column: ', 'target_item')\n",
      "('dtype before: ', dtype('int64'))\n",
      "('dtype after: ', dtype('int16'))\n",
      "******************************\n",
      "******************************\n",
      "('Column: ', 'target_lag_1')\n",
      "('dtype before: ', dtype('int64'))\n",
      "('dtype after: ', dtype('int16'))\n",
      "******************************\n",
      "******************************\n",
      "('Column: ', 'target_item_lag_1')\n",
      "('dtype before: ', dtype('int64'))\n",
      "('dtype after: ', dtype('int16'))\n",
      "******************************\n",
      "******************************\n",
      "('Column: ', 'target_shop_lag_1')\n",
      "('dtype before: ', dtype('int64'))\n",
      "('dtype after: ', dtype('uint16'))\n",
      "******************************\n",
      "******************************\n",
      "('Column: ', 'target_lag_2')\n",
      "('dtype before: ', dtype('int64'))\n",
      "('dtype after: ', dtype('int16'))\n",
      "******************************\n",
      "******************************\n",
      "('Column: ', 'target_item_lag_2')\n",
      "('dtype before: ', dtype('int64'))\n",
      "('dtype after: ', dtype('int16'))\n",
      "******************************\n",
      "******************************\n",
      "('Column: ', 'target_shop_lag_2')\n",
      "('dtype before: ', dtype('int64'))\n",
      "('dtype after: ', dtype('uint16'))\n",
      "******************************\n",
      "******************************\n",
      "('Column: ', 'target_lag_3')\n",
      "('dtype before: ', dtype('int64'))\n",
      "('dtype after: ', dtype('int16'))\n",
      "******************************\n",
      "******************************\n",
      "('Column: ', 'target_item_lag_3')\n",
      "('dtype before: ', dtype('int64'))\n",
      "('dtype after: ', dtype('int16'))\n",
      "******************************\n",
      "******************************\n",
      "('Column: ', 'target_shop_lag_3')\n",
      "('dtype before: ', dtype('int64'))\n",
      "('dtype after: ', dtype('uint16'))\n",
      "******************************\n",
      "******************************\n",
      "('Column: ', 'target_lag_12')\n",
      "('dtype before: ', dtype('int64'))\n",
      "('dtype after: ', dtype('int16'))\n",
      "******************************\n",
      "******************************\n",
      "('Column: ', 'target_item_lag_12')\n",
      "('dtype before: ', dtype('int64'))\n",
      "('dtype after: ', dtype('int16'))\n",
      "******************************\n",
      "******************************\n",
      "('Column: ', 'target_shop_lag_12')\n",
      "('dtype before: ', dtype('int64'))\n",
      "('dtype after: ', dtype('uint16'))\n",
      "******************************\n",
      "******************************\n",
      "('Column: ', 'item_category_id')\n",
      "('dtype before: ', dtype('int64'))\n",
      "('dtype after: ', dtype('uint8'))\n",
      "******************************\n",
      "___MEMORY USAGE AFTER COMPLETION:___\n",
      "('Memory usage is: ', 364, ' MB')\n",
      "('This is ', 23, '% of the initial size')\n"
     ]
    }
   ],
   "source": [
    "all_data, NAs = reduce_mem_usage(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test, NAs = reduce_mem_usage(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index_cols = ['shop_id', 'item_id', 'date_block_num']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# For every month we create a grid from all shops/items combinations from that month\n",
    "grid = [] \n",
    "for block_num in sales['date_block_num'].unique():\n",
    "    cur_shops = sales[sales['date_block_num']==block_num]['shop_id'].unique()\n",
    "    cur_items = sales[sales['date_block_num']==block_num]['item_id'].unique()\n",
    "    grid.append(np.array(list(product(*[cur_shops, cur_items, [block_num]])),dtype='int32'))\n",
    "\n",
    "#turn the grid into pandas dataframe\n",
    "grid = pd.DataFrame(np.vstack(grid), columns = index_cols,dtype=np.int32)\n",
    "\n",
    "#get aggregated values for (shop_id, item_id, month)\n",
    "gb = sales.groupby(index_cols,as_index=False).agg({'item_cnt_day':{'target':'sum'}})\n",
    "#fix column names\n",
    "gb.columns = [col[0] if col[-1]=='' else col[-1] for col in gb.columns.values]\n",
    "#join aggregated data to the grid\n",
    "all_data = pd.merge(grid,gb,how='left',on=index_cols).fillna(0)\n",
    "\n",
    "# Same as above but with shop-month aggregates\n",
    "gb = sales.groupby(['shop_id', 'date_block_num'],as_index=False).agg({'item_cnt_day':{'target_shop':'sum'}})\n",
    "gb.columns = [col[0] if col[-1]=='' else col[-1] for col in gb.columns.values]\n",
    "all_data = pd.merge(all_data, gb, how='left', on=['shop_id', 'date_block_num']).fillna(0)\n",
    "\n",
    "# Same as above but with item-month aggregates\n",
    "gb = sales.groupby(['item_id', 'date_block_num'],as_index=False).agg({'item_cnt_day':{'target_item':'sum'}})\n",
    "gb.columns = [col[0] if col[-1] == '' else col[-1] for col in gb.columns.values]\n",
    "all_data = pd.merge(all_data, gb, how='left', on=['item_id', 'date_block_num']).fillna(0)\n",
    "\n",
    "#sort the data\n",
    "all_data.sort_values(['date_block_num','shop_id','item_id'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_data, NAS = reduce_mem_usage(all_data)\n",
    "\n",
    "del grid, gb \n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data.to_csv('all_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# List of columns that we will use to create lags\n",
    "cols_to_rename = list(all_data.columns.difference(index_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cols_to_rename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lag months: 1 = last month sales; 12 = last year same month sales\n",
    "shift_range = [1,2,3,12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for month_shift in tqdm_notebook(shift_range):\n",
    "    train_shift = all_data[index_cols + cols_to_rename].copy()\n",
    "    \n",
    "    train_shift['date_block_num'] = train_shift['date_block_num'] + month_shift\n",
    "    \n",
    "    \n",
    "    \n",
    "    foo = lambda x: '{}_lag_{}'.format(x, month_shift) if x in cols_to_rename else x\n",
    "    train_shift = train_shift.rename(columns=foo)\n",
    "    \n",
    "    # Merge lag feature with train data\n",
    "    #all_data = pd.merge(all_data, train_shift, on=index_cols, how='left').fillna(0)\n",
    "    \n",
    "    # Merge lag feature with test data\n",
    "    test = pd.merge(test, train_shift, on=index_cols, how='left').fillna(0)\n",
    "    \n",
    "del train_shift\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "items = pd.read_csv(\"../input/items.csv\")\n",
    "#items, NAs = reduce_mem_usage(items)\n",
    "print items.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "items.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Category for each item\n",
    "item_category_mapping = items[['item_id','item_category_id']].drop_duplicates()\n",
    "\n",
    "all_data = pd.merge(all_data, item_category_mapping, how='left', on='item_id')\n",
    "\n",
    "test = pd.merge(test, item_category_mapping, how='left', on='item_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test, NAs = reduce_mem_usage(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test.to_csv('../input/test_1_2_3_12_cat.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_data, NAs = reduce_mem_usage(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data.to_csv('../input/all_data_1_2_3_12_cat.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['target_lag_1', 'target_item_lag_1', 'target_shop_lag_1', 'target_lag_2', 'target_item_lag_2', 'target_shop_lag_2', 'target_lag_3', 'target_item_lag_3', 'target_shop_lag_3', 'target_lag_12', 'target_item_lag_12', 'target_shop_lag_12', 'item_category_id']\n",
      "['target_item', 'target_shop', 'target', 'date_block_num']\n"
     ]
    }
   ],
   "source": [
    "# List of all lagged features\n",
    "fit_cols = [col for col in all_data.columns if col[-1] in [str(item) for item in shift_range]] \n",
    "fit_cols.append('item_category_id')\n",
    "# We will drop these at fitting stage\n",
    "to_drop_cols = list(set(list(all_data.columns)) - (set(fit_cols)|set(index_cols))) + ['date_block_num'] \n",
    "\n",
    "print fit_cols\n",
    "print to_drop_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train / Validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test `date_block_num` is 33\n"
     ]
    }
   ],
   "source": [
    "# Save `date_block_num`, as we can't use them as features, but will need them to split the dataset into parts \n",
    "dates = all_data['date_block_num']\n",
    "\n",
    "last_block = dates.max()\n",
    "print('Test `date_block_num` is %d' % last_block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lgb_params = {\n",
    "               'feature_fraction': 0.75,\n",
    "               'metric': 'rmse',\n",
    "               'n_jobs': -1, \n",
    "               'min_data_in_leaf': 2**7, \n",
    "               'bagging_fraction': 0.75, \n",
    "               'learning_rate': 0.03, \n",
    "               'objective': 'mse', \n",
    "               'bagging_seed': 2**7, \n",
    "               'num_leaves': 2**7,\n",
    "               'bagging_freq':1,\n",
    "               'verbose':0 \n",
    "              }\n",
    "\n",
    "lgb = LGBMRegressor(**lgb_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Month 33 Test R-2: 0.113460\n",
      "Month 33 Test RMSE 5.030523\n",
      "Month 32 Test R-2: 0.047766\n",
      "Month 32 Test RMSE 6.682272\n",
      "Month 31 Test R-2: 0.343891\n",
      "Month 31 Test RMSE 1.811004\n",
      "Month 30 Test R-2: 0.417466\n",
      "Month 30 Test RMSE 1.632446\n",
      "Month 29 Test R-2: 0.359447\n",
      "Month 29 Test RMSE 1.863724\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "447"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Moving window validation scheme.\n",
    "# On each iteration, use last month for validation\n",
    "validation_months = [33, 32, 31, 30, 29]\n",
    "\n",
    "for last_month in validation_months:\n",
    "    # Split train and validation data\n",
    "    dates_train = dates[dates <  last_month]\n",
    "    dates_test  = dates[dates == last_month]\n",
    "\n",
    "    X_train = all_data.loc[dates <  last_month].drop(to_drop_cols, axis=1)\n",
    "    X_test =  all_data.loc[dates == last_month].drop(to_drop_cols, axis=1)\n",
    "\n",
    "    y_train = all_data.loc[dates <  last_month, 'target'].values\n",
    "    y_test =  all_data.loc[dates == last_month, 'target'].values\n",
    "    \n",
    "    lgb.fit(X_train, y_train)\n",
    "\n",
    "    pred_train = lgb.predict(X_train)\n",
    "    pred_test = lgb.predict(X_test)\n",
    "    \n",
    "    ## R2 and RMSE score for each validation fold\n",
    "    print('Month {0:d} Test R-2: {1:f}'.format(last_month, r2_score(y_test, pred_test)))\n",
    "    print('Month {0:d} Test RMSE {1:f}'.format(last_month, np.sqrt(mean_squared_error(y_test, pred_test))))\n",
    "    \n",
    "del dates_train, dates_test, X_train, X_test, y_train, y_test, pred_train, pred_test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Take all train data\n",
    "X_train_all = all_data.drop(to_drop_cols, axis=1)\n",
    "y_train_all = all_data.target.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_all.target_lag_1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test.sort(columns='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_id = test.pop('ID')\n",
    "test.drop('date_block_num', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lgb.fit(X_train_all, y_train_all)\n",
    "\n",
    "pred_train_all = lgb.predict(X_train_all)\n",
    "pred_test = lgb.predict(test)\n",
    "\n",
    "## R2 and RMSE score for each validation fold\n",
    "print('Train R-2: {0:f}'.format(r2_score(y_train_all, pred_train_all)))\n",
    "print('Train RMSE {0:f}'.format(np.sqrt(mean_squared_error(y_train_all, pred_train_all))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(pred_test)):\n",
    "    if pred_test[i] > 20:\n",
    "        pred_test[i] = 20\n",
    "    if pred_test[i] < 0:\n",
    "        pred_test[i] = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_submit = pd.DataFrame({'ID': test_id, 'item_cnt_month': pred_test})\n",
    "print test_submit.shape\n",
    "test_submit.to_csv('lgbm_1_2_3_12_cat.csv', index=False)\n",
    "test_submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "widgets": {
   "state": {
    "e4e38e6559a744069f89202daa1b4dca": {
     "views": [
      {
       "cell_index": 18
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
